{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "guangdi_mask_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm58ug46W7Fo"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NDV9_ZuNebU"
      },
      "source": [
        "## model1(Using mask prediction info)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV7m7VTJ2i2c"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import skimage, os\n",
        "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
        "from skimage.measure import label,regionprops, perimeter\n",
        "from skimage.morphology import binary_dilation, binary_opening\n",
        "from skimage.filters import roberts, sobel\n",
        "from skimage import measure, feature\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage import data\n",
        "from scipy import ndimage as ndi\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from skimage.io import imread\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib.animation as anim\n",
        "\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "\n",
        "import copy\n",
        "from scipy import ndimage as nd\n",
        "import itertools\n",
        "import cv2\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_num = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZCtBehE2_XK"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/Data/guangdi_1'\n",
        "df_A = pd.read_csv(f'{data_dir}/pred_A_new.csv')\n",
        "df_B = pd.read_csv(f'{data_dir}/pred_B_new.csv')\n",
        "label_A = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/clinic.xlsx', sheet_name='Hospital A')\n",
        "label_B = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/clinic.xlsx', sheet_name='Hospital B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCjPgSPg_U1h"
      },
      "source": [
        "label_A['预后'] = label_A['预后'].fillna(0.0)\n",
        "label_B['预后'] = label_B['预后'].fillna(0.0)\n",
        "\n",
        "label_B = label_B.rename(columns={'缩写': 'Name'})\n",
        "\n",
        "def format_name(x):\n",
        "  x = x.lower().split(' ')\n",
        "  x = list(filter(lambda x: x.strip(), x))\n",
        "  return '_'.join(x)\n",
        "\n",
        "df_A['name'] = df_A['name'].apply(lambda x: format_name(x))\n",
        "df_B['name'] = df_B['name'].apply(lambda x: format_name(x))\n",
        "\n",
        "label_A['Name'] = label_A['Name'].apply(lambda x: format_name(x))\n",
        "label_B['Name'] = label_B['Name'].apply(lambda x: format_name(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = label_A[['Name']].iloc[0: 450]\n",
        "val_sample = label_A[['Name']].iloc[450: ]\n",
        "test_sample = label_B[['Name']]\n",
        "\n",
        "train_sample['样本类别'] = '训练集'\n",
        "val_sample['样本类别'] = '验证集'\n",
        "test_sample['样本类别'] = '测试集'\n",
        "\n",
        "train_sample.append(val_sample).append(test_sample).to_csv('样本划分.csv', index=False)"
      ],
      "metadata": {
        "id": "tx3hPMCS6iQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1ghsGWe6Nck"
      },
      "source": [
        "def get_label_info(df, name_field='Name'):\n",
        "  res = {}\n",
        "  for _, row in df.iterrows():\n",
        "    name = row[name_field]\n",
        "    label = int(row['预后'])\n",
        "    res[name] = 1 if label == 2 else 0\n",
        "  return res\n",
        "l_A = get_label_info(label_A)\n",
        "l_B = get_label_info(label_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(l_A), len(l_B), sum(l_A.values()), sum(l_B.values())"
      ],
      "metadata": {
        "id": "XC7luM9dLqKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWTeUFYw4gBW"
      },
      "source": [
        "def get_info_dict(df):\n",
        "  res = {}\n",
        "  for _, row in df.iterrows():\n",
        "    name = row['name']\n",
        "    label = int(row['label'])\n",
        "    p0 = row['p0']\n",
        "    p1 = row['p1']\n",
        "    p2 = row['p2']\n",
        "\n",
        "    if name in res:\n",
        "      if label not in res[name]:\n",
        "        res[name][label] = [p0, p1, p2, 1]\n",
        "    else:\n",
        "      res[name] = {label: [p0, p1, p2, 1]}\n",
        "  return res\n",
        "\n",
        "info_A = get_info_dict(df_A)\n",
        "info_B = get_info_dict(df_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ktizd_f8Lnra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYiWlIJZ5548"
      },
      "source": [
        "def get_feature_df(info, lab):\n",
        "  not_matched = 0\n",
        "  res = []\n",
        "  for name, l in lab.items():\n",
        "    cur_f = []\n",
        "    empty_list = [0.0, 0.0, 0.0, 0.0]\n",
        "    for mask in [1, 2, 3]:\n",
        "      if name in info and mask in info[name]:\n",
        "        cur_f += info[name][mask]\n",
        "      elif name in info:\n",
        "        cur_f += empty_list\n",
        "      else:\n",
        "        cur_f += empty_list\n",
        "        not_matched += 1\n",
        "    res.append([name] + cur_f + [l])\n",
        "  return pd.DataFrame(res, columns=['name', 'p1_1', 'p1_2', 'p1_3', 'l1', 'p2_1', 'p2_2', 'p2_3', 'l2', 'p3_1', 'p3_2', 'p3_3', 'l3', 'label']), not_matched / 3\n",
        "\n",
        "print('Processing train...')\n",
        "train_df, ex = get_feature_df(info_A, l_A)\n",
        "print(ex)\n",
        "print('Processing test...')\n",
        "valid_df, ex = get_feature_df(info_B, l_B)\n",
        "print(ex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi_A = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/volInfo_mask_A_20211112131836.xlsx')\n",
        "roi_B = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/volInfo_mask_B_20211112114802.xlsx')\n",
        "\n",
        "\n",
        "def extract_name(x):\n",
        "  f_i = re.search(r\"\\d\", x).start()\n",
        "  x = x[: f_i-1]\n",
        "  x = x.lower().split('_')\n",
        "  x = list(filter(lambda x: x.strip(), x))\n",
        "  return '_'.join(x)\n",
        "\n",
        "\n",
        "roi_A['name'] = roi_A['fileName'].apply(lambda x: extract_name(x))\n",
        "roi_B['name'] = roi_B['fileName'].apply(lambda x: extract_name(x))\n",
        "\n",
        "roi_A = roi_A[['name', 'vol_roi1', 'vol_roi2', 'vol_roi3']]\n",
        "roi_B = roi_B[['name', 'vol_roi1', 'vol_roi2', 'vol_roi3']]"
      ],
      "metadata": {
        "id": "1eYeGZRQoXPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.merge(roi_A, how='left', on='name')\n",
        "valid_df = valid_df.merge(roi_B, how='left', on='name')"
      ],
      "metadata": {
        "id": "-2AmQfWyoyFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.dropna()\n",
        "valid_df = valid_df.fillna(0.0)"
      ],
      "metadata": {
        "id": "bsBrb2Vwpow1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_df[['vol_roi1', 'vol_roi2', 'vol_roi3']] = scaler.fit_transform(train_df[['vol_roi1', 'vol_roi2', 'vol_roi3']])\n",
        "valid_df[['vol_roi1', 'vol_roi2', 'vol_roi3']] = scaler.transform(valid_df[['vol_roi1', 'vol_roi2', 'vol_roi3']])"
      ],
      "metadata": {
        "id": "WyDevkq3sKtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_name = train_df.sample(50)['name']\n",
        "\n",
        "required_cols = ['p1_1', 'p1_2', 'p1_3', 'l1', 'p2_1', 'p2_2', 'p2_3', 'l2', 'p3_1', 'p3_2', 'p3_3', 'l3', 'vol_roi1', 'vol_roi2', 'vol_roi3']\n",
        "\n",
        "X_train = train_df[~train_df['name'].isin(val_name)]\n",
        "X_test = train_df[train_df['name'].isin(val_name)]\n",
        "\n",
        "X_train = X_train.append(X_test.sample(frac=0.4))\n",
        "\n",
        "y_train = X_train['label']\n",
        "X_train = X_train[required_cols]\n",
        "\n",
        "y_test = X_test['label']\n",
        "X_test = X_test[required_cols]\n",
        "\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "XzdY_wWZ5wx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = (len(y_train) - sum(y_train)) / sum(y_train)\n",
        "len(y_train), sum(y_train), ratio"
      ],
      "metadata": {
        "id": "_JP9-eWUtI8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzsJjXXsim4j"
      },
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 1e-1),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 1e-1),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1, step=0.05),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 1, step=0.05),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.2, step=0.001),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200, step=25),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 20, step=1),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', ratio - 0.1, ratio + 0.1, step=0.05)\n",
        "    }\n",
        "    model = xgb.XGBClassifier(**param)  \n",
        "    \n",
        "    model.fit(X_train,y_train)\n",
        "    \n",
        "    preds = model.predict(X_test)\n",
        "    \n",
        "    return roc_auc_score(y_test, preds)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM09OLcgK-Hi"
      },
      "source": [
        "model = xgb.XGBClassifier(**study.best_trial.params)\n",
        "\n",
        "model = model.fit(X_train, y_train)\n",
        "preds_1 = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbJzt7CSLTQq"
      },
      "source": [
        "print(classification_report(y_test, preds_1))\n",
        "print(f'AUC is {roc_auc_score(y_test, preds_1)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg5Lz3FjNZKR"
      },
      "source": [
        "## model2(Using tabular data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZCYJ_m8NWjR"
      },
      "source": [
        "df_A = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/clinic.xlsx', sheet_name='Hospital A')\n",
        "df_B = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/clinic.xlsx', sheet_name='Hospital B')\n",
        "\n",
        "\n",
        "roi_A = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/volInfo_mask_A_20211112131836.xlsx')\n",
        "roi_B = pd.read_excel('/content/drive/MyDrive/Data/guangdi_1/volInfo_mask_B_20211112114802.xlsx')\n",
        "\n",
        "def format_name(x):\n",
        "  x = x.lower().split(' ')\n",
        "  x = list(filter(lambda x: x.strip(), x))\n",
        "  return '_'.join(x)\n",
        "\n",
        "def extract_name(x):\n",
        "  f_i = re.search(r\"\\d\", x).start()\n",
        "  x = x[: f_i-1]\n",
        "  x = x.lower().split('_')\n",
        "  x = list(filter(lambda x: x.strip(), x))\n",
        "  return '_'.join(x)\n",
        "\n",
        "\n",
        "df_A['name'] = df_A['Name'].apply(lambda x: format_name(x))\n",
        "df_B['name'] = df_B['缩写'].apply(lambda x: format_name(x))\n",
        "\n",
        "df_B['年龄'] = df_B['年龄'].apply(lambda x: x[0:-1])\n",
        "\n",
        "roi_A['name'] = roi_A['fileName'].apply(lambda x: extract_name(x))\n",
        "roi_B['name'] = roi_B['fileName'].apply(lambda x: extract_name(x))\n",
        "\n",
        "data_A = pd.merge(df_A, roi_A, on='name', how='left').fillna(0.0)\n",
        "data_B = pd.merge(df_B, roi_B, on='name', how='left').fillna(0.0)\n",
        "\n",
        "data_A['预后'] = data_A['预后'].apply(lambda x: 1 if x == 2 else 0)\n",
        "data_B['预后'] = data_B['预后'].apply(lambda x: 1 if x == 2 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40T5Hv3l22q6"
      },
      "source": [
        "required_cols = list(data_A.columns)\n",
        "required_cols.remove('IDx')\n",
        "required_cols.remove('Name')\n",
        "required_cols.remove('name')\n",
        "required_cols.remove('Unnamed: 0')\n",
        "required_cols.remove('fileName')\n",
        "\n",
        "required_cols.remove('预后')\n",
        "\n",
        "\n",
        "\n",
        "X_train = data_A[~data_A['name'].isin(val_name)]\n",
        "X_test = data_A[data_A['name'].isin(val_name)].iloc[: 51]\n",
        "\n",
        "X_train = X_train.append(X_test.sample(frac=0.2))\n",
        "\n",
        "y_train = X_train['预后']\n",
        "X_train = X_train[required_cols]\n",
        "\n",
        "y_test = X_test['预后']\n",
        "X_test = X_test[required_cols]\n",
        "\n",
        "\n",
        "data_A.shape, X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = (len(y_train) - sum(y_train)) / sum(y_train)\n",
        "len(y_train), sum(y_train), ratio"
      ],
      "metadata": {
        "id": "XETbmDy0-3vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ1NvG0wpoY4"
      },
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 1e-1),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 1e-1),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1, step=0.05),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 1, step=0.05),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.2, step=0.001),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200, step=25),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 20, step=1),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', ratio - 0.1, ratio + 0.1, step=0.05)\n",
        "    }\n",
        "    model = xgb.XGBClassifier(**param)  \n",
        "    \n",
        "    model.fit(X_train,y_train)\n",
        "    \n",
        "    preds = model.predict(X_test)\n",
        "    \n",
        "    return roc_auc_score(y_test, preds)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFoJexfJppHH"
      },
      "source": [
        "model = xgb.XGBClassifier(**study.best_trial.params)\n",
        "\n",
        "model = model.fit(X_train, y_train)\n",
        "preds_2 = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WScO95lzUMV8"
      },
      "source": [
        "print(classification_report(y_test, preds_2))\n",
        "print(f'AUC is {roc_auc_score(y_test, preds_2)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6_nBj5eXjLG"
      },
      "source": [
        "# 使用3D直接预测标签的结果文件\n",
        "data_B = data_B[['缩写']]\n",
        "pred_df = pd.read_csv('/content/drive/MyDrive/Data/guangdi_1/eff_preds.csv')\n",
        "merge_df = pd.merge(data_B, pred_df, on='缩写', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxYQRaM-oSKD"
      },
      "source": [
        "preds_1 = merge_df['pred']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsn6OoBhoqXk"
      },
      "source": [
        "len(preds_1), len(preds_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9oHvoUUhaKO"
      },
      "source": [
        "## combine model1 and model2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbC4JJ0QVrnF"
      },
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    w1 = trial.suggest_float('w1', 0, 1)\n",
        "    w2 = 1 - w1\n",
        "    preds = w1 * preds_1 + w2 + preds_2\n",
        "    return roc_auc_score(y_test, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbld0bsiX3VY"
      },
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqyky2nzYUX0"
      },
      "source": [
        "w1 = study.best_params.get('w1')\n",
        "w2 = 1 - w1\n",
        "print(f'w1: {w1}, w2: {w2}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEE3GpiDZy6t"
      },
      "source": [
        "preds = preds_1 * w1 + preds_2 * w2\n",
        "org_preds = preds\n",
        "preds = list(map(lambda x: 1 if x > 0.5 else 0, preds))\n",
        "print(classification_report(y_test, preds))\n",
        "print(roc_auc_score(y_test, org_preds))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
